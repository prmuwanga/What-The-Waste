{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import load_img\n",
    "from sklearn.metrics import classification_report \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os \n",
    "import shutil \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18042 images belonging to 13 classes.\n",
      "{'battery': 0, 'biological': 1, 'brown-glass': 2, 'cardboard': 3, 'clothes': 4, 'glass': 5, 'green-glass': 6, 'metal': 7, 'paper': 8, 'plastic': 9, 'shoes': 10, 'trash': 11, 'white-glass': 12}\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Turning every folder name into class label\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    \"../Datasets/combined-cleaned-dataset\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode= \"categorical\"\n",
    ")\n",
    "\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " paper: 1150 train / 246 val / 248 test\n",
      " green-glass: 440 train / 94 val / 95 test\n",
      " clothes: 3727 train / 798 val / 800 test\n",
      " metal: 825 train / 176 val / 178 test\n",
      " cardboard: 905 train / 194 val / 195 test\n",
      " trash: 583 train / 125 val / 126 test\n",
      " glass: 350 train / 75 val / 76 test\n",
      " biological: 689 train / 147 val / 149 test\n",
      " white-glass: 542 train / 116 val / 117 test\n",
      " battery: 661 train / 141 val / 143 test\n",
      " brown-glass: 424 train / 91 val / 92 test\n",
      " plastic: 942 train / 202 val / 203 test\n",
      " shoes: 1383 train / 296 val / 298 test\n"
     ]
    }
   ],
   "source": [
    "# Spliting our dataset into training, validation, and testing \n",
    "# we asked chatgpt for help with spliting and combining our 2 dataset into the same categories specifically with using os makedir for the folders and how to use the program shutil \n",
    "\n",
    "\n",
    "#requirement and readme do them \n",
    "\n",
    "def split_dataset(source_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    random.seed(42)\n",
    "    \n",
    "    for class_folder in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue \n",
    "        \n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "        random.shuffle(images)\n",
    "    \n",
    "        total = len(images)\n",
    "        train_end = int(total * train_ratio)\n",
    "        val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "        train_images = images[:train_end]\n",
    "        val_images = images[train_end:val_end]\n",
    "        test_images = images[val_end:]\n",
    "    \n",
    "        train_class_dir = os.path.join(output_dir, 'train', class_folder)\n",
    "        val_class_dir = os.path.join(output_dir, 'val', class_folder)\n",
    "        test_class_dir = os.path.join(output_dir,'test',class_folder)\n",
    "    \n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "        for img in train_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(train_class_dir, img))\n",
    "\n",
    "        for img in val_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(val_class_dir, img))\n",
    "\n",
    "        for img in test_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(test_class_dir, img))\n",
    "\n",
    "        print(f\" {class_folder}: {len(train_images)} train / {len(val_images)} val / {len(test_images)} test\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    source = \"../Datasets/combined-cleaned-dataset\"   \n",
    "    destination = \"../Notebooks/the_final_sortdown\"          \n",
    "    split_dataset(source, destination, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Found 16410 images belonging to 13 classes.\n",
      "\n",
      "Validation Data:\n",
      "Found 4985 images belonging to 13 classes.\n",
      "\n",
      "Testing Data:\n",
      "Found 5047 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    brightness_range = [0.8, 1.2]\n",
    ")\n",
    "\n",
    "# training data \n",
    "print(\"Training Data:\")\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/train\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# validation\n",
    "print(\"\\nValidation Data:\")\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/val\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#testing \n",
    "print(\"\\nTesting Data:\")\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/test\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    include_top = False,\n",
    "    weights ='imagenet',\n",
    "    input_shape = (224,224,3) #images shape 224x224 pixels \n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "num_classes = len(train_data.class_indices)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(), # optimizers \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing early stopping to avoid to overfitting \n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,          \n",
    "    restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindychen/.pyenv/versions/3.9.16/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 226ms/step - accuracy: 0.7679 - loss: 0.7594 - val_accuracy: 0.8987 - val_loss: 0.3101\n",
      "Epoch 2/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 232ms/step - accuracy: 0.8897 - loss: 0.3254 - val_accuracy: 0.9163 - val_loss: 0.2405\n",
      "Epoch 3/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 234ms/step - accuracy: 0.9067 - loss: 0.2612 - val_accuracy: 0.9284 - val_loss: 0.2038\n",
      "Epoch 4/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 228ms/step - accuracy: 0.9180 - loss: 0.2243 - val_accuracy: 0.9316 - val_loss: 0.1908\n",
      "Epoch 5/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 234ms/step - accuracy: 0.9259 - loss: 0.2044 - val_accuracy: 0.9388 - val_loss: 0.1775\n",
      "Epoch 6/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 222ms/step - accuracy: 0.9371 - loss: 0.1742 - val_accuracy: 0.9408 - val_loss: 0.1613\n",
      "Epoch 7/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 226ms/step - accuracy: 0.9388 - loss: 0.1559 - val_accuracy: 0.9418 - val_loss: 0.1592\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs = 7, \n",
    "    callbacks = [early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - accuracy: 0.9509 - loss: 0.1257\n",
      "Test accuarcy: 0.94\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f\"Test accuarcy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.98      0.97      0.97       265\n",
      "  biological       0.99      0.98      0.98       268\n",
      " brown-glass       0.80      0.92      0.85       173\n",
      "   cardboard       0.98      0.94      0.96       360\n",
      "     clothes       0.99      0.99      0.99      1493\n",
      "       glass       0.46      0.16      0.23       140\n",
      " green-glass       0.86      0.87      0.86       175\n",
      "       metal       0.97      0.92      0.94       333\n",
      "       paper       0.96      0.98      0.97       470\n",
      "     plastic       0.95      0.91      0.93       381\n",
      "       shoes       0.96      0.99      0.97       545\n",
      "       trash       0.96      0.94      0.95       235\n",
      " white-glass       0.64      0.94      0.76       209\n",
      "\n",
      "    accuracy                           0.94      5047\n",
      "   macro avg       0.88      0.88      0.88      5047\n",
      "weighted avg       0.94      0.94      0.93      5047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding Precision, Recall, and F1\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(test_data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_data.classes\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.heading', 'Unnamed: 2', '..1', 'Unnamed: 4', 'Process', 'Total', 'Total.1', 'eco-costs of', 'eco-costs of.1', 'eco-costs of.2', 'eco-costs of.3', 'Carbon ', 'Carbon .1', 'CED', 'ReCiPe2016', 'ReCiPe2016.1', 'ReCiPe', 'ReCiPe.1', 'ReCiPe.2', 'ReCiPe.3', 'ReCiPe.4', 'ReCiPe.5', 'EF 3.1', 'EF 3.1.1', 'carbon', 'pollutants', 'water', 'biodiversity', 'resources', 'ClassyFire', 'chemicals,plastics, and wood', 'Note:', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset for RL\n",
    "df = pd.read_csv(\"../Datasets/Idemat_2025RevA6.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Finding the columns names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data \n",
    "df_filtered = df[[\"Process\", \"carbon\"]].copy()\n",
    "df_filtered.columns = [\"process\", \"co2_kg\"]\n",
    "\n",
    "# Strip whitespace, convert types\n",
    "df_filtered[\"process\"] = df_filtered[\"process\"].str.strip()\n",
    "df_filtered[\"co2_kg\"] = pd.to_numeric(df_filtered[\"co2_kg\"], errors=\"coerce\")\n",
    "\n",
    "# Drop bad rows\n",
    "df_filtered.dropna(subset=[\"process\", \"co2_kg\"], inplace=True)\n",
    "\n",
    "# Build lookup\n",
    "co2_lookup = dict(zip(df_filtered[\"process\"], df_filtered[\"co2_kg\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete\n",
    "\n",
    "# mapping items names from dataset to categories from our CNN\n",
    "cnn_class_to_process = {\n",
    "    \"plastic\": [\n",
    "        \"Carbon fiber-reinforced plastic chopped - for reinforcing plastics\",\n",
    "        \"Glassfibre - Metals open loop recycling credit dry\"\n",
    "    ],\n",
    "    \"metal\": [\n",
    "        \"Zinc (super plastic)\",\n",
    "        \"Lead battery cars (39 Wh per kg)\", \n",
    "        \"Aluminium  recycling credit closed loop (79% virgin part trade mix)\", \n",
    "        \"Aluminium  recycling credit closed loop (79% virgin part trade mix)\", \n",
    "        \"Gold  recycling credit closed loop (80% virgin part trade mix)\", \n",
    "        \"Magnesium  recycling credit closed loop (90% virgin part in trade mix)\", \n",
    "        \"Nickel  recycling credit closed loop (66% virgin part in trade mix)\", \n",
    "        \"Platinum  recycling credit  closed loop (88.5% virgin part in trade mix)\",\n",
    "        \"Silver  recycling credit closed loop (45% virgin part trade mix)\", \n",
    "        \"Titanium  recycling credit  closed loop (81% virgin part in trade mix)\", \n",
    "        \"Palladium  recycling credit  closed loop (91% virgin part in trade mix)\"\n",
    "        \n",
    "    ],\n",
    "    \"cardboard\": [\n",
    "        \"Corrugated board - unbleached\",\n",
    "        \"Corrugated board - bleached\"\n",
    "    ],\n",
    "    \"glass\": [\n",
    "        \"Glass - packaging clear\",\n",
    "        \"Glass - packaging mixed\"\n",
    "    ],\n",
    "    \"paper\": [\n",
    "        \"Paper - office, recycled\"\n",
    "    ],\n",
    "    \"clothes\": [\n",
    "        \"Cotton fibres India - rainfed\",\n",
    "        \"Cotton fibres Bangladesh - rainfed\", \n",
    "        \"Cotton fibre from USA (without global seatransport)\", \n",
    "        \"Wool from Australia - transported to Rotterdam\"\n",
    "        \n",
    "    ],\n",
    "    \"shoes\": [\n",
    "        \"Leather Vegetable tanning - hides from Europe\",\n",
    "        \"Leather Chrome tanning - hides from Argentina\"\n",
    "    ],\n",
    "    \"battery\": [\n",
    "        \"AA cell battery (Alkaline)\",\n",
    "        \"AA cell battery (Li-ion)\",\n",
    "        \"NiCd battery AA-cell\",\n",
    "        \"NiCd battery C-cell\",\n",
    "        \"Lithium-ion LiCoO2 laptop battery (180 Wh/kg)\",\n",
    "        \"Lead battery cars (39 Wh per kg)\"\n",
    "    ],\n",
    "    \"biological\": [\n",
    "        \"Baguette white\",\n",
    "        \"Bread multigrain\",\n",
    "        \"Bread rye\" ,\n",
    "        \"Crispbread\",\n",
    "        \"White bread hard\", \n",
    "        \"White bread soft\", \n",
    "        \"Zucchini\", \n",
    "        \"Broccoli\", \n",
    "        \"Tomato\", \n",
    "        \"Popcorn\",\n",
    "        \"Cake without butter\"\n",
    "        \n",
    "    ],\n",
    "    \"trash\": [\n",
    "        \"Cake with butter\",\n",
    "        \"Residual waste - incinerated\"\n",
    "    ],\n",
    "    \"brown-glass\": [\n",
    "        \"Beer (bottle)\"\n",
    "        \n",
    "    ],\n",
    "    \"green-glass\": [\n",
    "        \"Beer (bottle)\"\n",
    "    ],\n",
    "    \"white-glass\": [\n",
    "        \"Beer (bottle)\", \n",
    "        \"Young gin\",\n",
    "        \"Wine rose\", \n",
    "        \"Wine white dry\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "#iniliaze empty dictionary for labels\n",
    "cnn_class_to_co2 = {}\n",
    "\n",
    "for label, materials in cnn_class_to_process.items():\n",
    "    if isinstance(materials, list):\n",
    "        values = [co2_lookup.get(m) for m in materials if m in co2_lookup]\n",
    "        values = [v for v in values if pd.notna(v)]  # drop NaNs\n",
    "        if values:\n",
    "            cnn_class_to_co2[label] = sum(values) / len(values)  # average\n",
    "        else:\n",
    "            cnn_class_to_co2[label] = 1.0\n",
    "    else:\n",
    "        value = co2_lookup.get(materials, 1.0)\n",
    "        cnn_class_to_co2[label] = float(value) if pd.notna(value) else 1.0\n",
    "\n",
    "\n",
    "# mapping different actions for the RL 0 meaning recycle and 3 is compost\n",
    "correct_actions = {\n",
    "    \"cardboard\": 0,   # Recycle\n",
    "    \"clothes\": 1,     # Donate\n",
    "    \"battery\": 4,     # Hazardous\n",
    "    \"brown-glass\":0,  # Recycle\n",
    "    \"glass\": 0,       # Recycle\n",
    "    \"green-glass\" : 0,# Recycle\n",
    "    \"metal\": 0,       # Recycle\n",
    "    \"paper\": 0,       # Recycle\n",
    "    \"plastic\": 0,     # Recycle\n",
    "    \"shoes\": 1,       # Donate\n",
    "    \"white-glass\": 0, # Recycle \n",
    "    \"trash\" : 2,      # Landfill\n",
    "    \"biological\": 3   # Compost\n",
    "    \n",
    "}\n",
    "\n",
    "#creating environment for RL \n",
    "class WasteDisposalEnv(Env):\n",
    "    def __init__(self, cnn_class_to_co2, correct_actions):\n",
    "        super(WasteDisposalEnv, self).__init__()\n",
    "        self.cnn_class_to_co2 = cnn_class_to_co2\n",
    "        self.correct_actions = correct_actions\n",
    "        self.classes = list(cnn_class_to_co2.keys())\n",
    "        self.action_space = Discrete(5)  # [Recycle, Donate, Landfill, Compost, Hazardous]\n",
    "        self.observation_space = Discrete(len(self.classes))\n",
    "        self.current_class = None\n",
    "        \n",
    "    # Initialize stats tracker\n",
    "        self.stats = {\n",
    "            \"white-glass_recyclable\": 0,\n",
    "            \"white-glass_nonrecyclable\": 0\n",
    "        }\n",
    "        \n",
    " # need reset, step, commonly used for gymnasium environment \n",
    "    def reset(self, seed=None, options=None):\n",
    "        # makes a random waste selection for a new episode \n",
    "        super().reset(seed=seed)\n",
    "        self.current_class = random.choice(self.classes)\n",
    "          # Return its index as the observation\n",
    "        obs = self.classes.index(self.current_class)\n",
    "        return obs,{}\n",
    "\n",
    "    def step(self, action):\n",
    "        co2 = self.cnn_class_to_co2[self.current_class]\n",
    "        \n",
    "          # correct disposal action for this waste class\n",
    "        correct_action = self.correct_actions.get(self.current_class, 2) \n",
    "          \n",
    "        # Special case: white-glass may be recyclable or not (adds uncertainty)\n",
    "         # rewards \n",
    "        if self.current_class == \"white-glass\":\n",
    "            if random.random() < 0.8:\n",
    "                correct_action = 0  # Recyclable\n",
    "                self.stats[\"white-glass_recyclable\"] += 1\n",
    "            else:\n",
    "                correct_action = 2  # Non-recyclable\n",
    "                self.stats[\"white-glass_nonrecyclable\"] += 1\n",
    "\n",
    "        reward = co2 if action == correct_action else -co2\n",
    "        #episode ending for each decision \n",
    "        terminated = True\n",
    "        truncated = False\n",
    "        \n",
    "        # starts a new episode with a waste item \n",
    "        obs, _ = self.reset()\n",
    "        \n",
    "         #Return observation, reward\n",
    "        return obs, reward, terminated, truncated, {\n",
    "            \"class\": self.current_class,\n",
    "            \"co2\": co2,\n",
    "            \"action\": action,\n",
    "            \"correct\": correct_action\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -0.768   |\n",
      "| time/              |          |\n",
      "|    fps             | 6542     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | -0.514     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 4326       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 0          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04795645 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | -0.118     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.39       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.1       |\n",
      "|    value_loss           | 1.29       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.0343     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 4096       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06632918 |\n",
      "|    clip_fraction        | 0.867      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | -0.0213    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.966      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.146     |\n",
      "|    value_loss           | 1.58       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.276      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3969       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06934939 |\n",
      "|    clip_fraction        | 0.928      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -0.0538    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.565      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.163     |\n",
      "|    value_loss           | 1.81       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.924      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3789       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11369525 |\n",
      "|    clip_fraction        | 0.898      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.636     |\n",
      "|    explained_variance   | 0.0918     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.601      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.155     |\n",
      "|    value_loss           | 1.47       |\n",
      "----------------------------------------\n",
      "Predicted class: cardboard, Action: 0, Reward: 0.440354645\n",
      "Predicted class: brown-glass, Action: 0, Reward: -1.0\n",
      "Predicted class: brown-glass, Action: 4, Reward: 2.5956188898\n",
      "Predicted class: white-glass, Action: 1, Reward: 2.6950868\n",
      "Predicted class: white-glass, Action: 4, Reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "env = WasteDisposalEnv(cnn_class_to_co2, correct_actions)\n",
    "check_env(env)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "model.save(\"ppo_waste_disposal\")\n",
    "\n",
    "# Test\n",
    "obs, _ = env.reset()\n",
    "for _ in range(5):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(f\"Predicted class: {info['class']}, Action: {action}, Reward: {reward}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
