{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import load_img\n",
    "from sklearn.metrics import classification_report \n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os \n",
    "import shutil \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18042 images belonging to 13 classes.\n",
      "{'battery': 0, 'biological': 1, 'brown-glass': 2, 'cardboard': 3, 'clothes': 4, 'glass': 5, 'green-glass': 6, 'metal': 7, 'paper': 8, 'plastic': 9, 'shoes': 10, 'trash': 11, 'white-glass': 12}\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Turning every folder name into class label\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    \"../Datasets/combined-cleaned-dataset\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode= \"categorical\"\n",
    ")\n",
    "\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " paper: 1150 train / 246 val / 248 test\n",
      " green-glass: 440 train / 94 val / 95 test\n",
      " clothes: 3727 train / 798 val / 800 test\n",
      " metal: 825 train / 176 val / 178 test\n",
      " cardboard: 905 train / 194 val / 195 test\n",
      " trash: 583 train / 125 val / 126 test\n",
      " glass: 350 train / 75 val / 76 test\n",
      " biological: 689 train / 147 val / 149 test\n",
      " white-glass: 542 train / 116 val / 117 test\n",
      " battery: 661 train / 141 val / 143 test\n",
      " brown-glass: 424 train / 91 val / 92 test\n",
      " plastic: 942 train / 202 val / 203 test\n",
      " shoes: 1383 train / 296 val / 298 test\n"
     ]
    }
   ],
   "source": [
    "# Spliting our dataset into training, validation, and testing \n",
    "def split_dataset(source_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    random.seed(42)\n",
    "    \n",
    "    for class_folder in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_folder)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue \n",
    "        \n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "        random.shuffle(images)\n",
    "    \n",
    "        total = len(images)\n",
    "        train_end = int(total * train_ratio)\n",
    "        val_end = train_end + int(total * val_ratio)\n",
    "    \n",
    "        train_images = images[:train_end]\n",
    "        val_images = images[train_end:val_end]\n",
    "        test_images = images[val_end:]\n",
    "    \n",
    "        train_class_dir = os.path.join(output_dir, 'train', class_folder)\n",
    "        val_class_dir = os.path.join(output_dir, 'val', class_folder)\n",
    "        test_class_dir = os.path.join(output_dir,'test',class_folder)\n",
    "    \n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "        for img in train_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(train_class_dir, img))\n",
    "\n",
    "        for img in val_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(val_class_dir, img))\n",
    "\n",
    "        for img in test_images:\n",
    "            shutil.copy2(os.path.join(class_path, img), os.path.join(test_class_dir, img))\n",
    "\n",
    "        print(f\" {class_folder}: {len(train_images)} train / {len(val_images)} val / {len(test_images)} test\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    source = \"../Datasets/combined-cleaned-dataset\"   \n",
    "    destination = \"../Notebooks/the_final_sortdown\"          \n",
    "    split_dataset(source, destination, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Found 16410 images belonging to 13 classes.\n",
      "\n",
      "Validation Data:\n",
      "Found 4985 images belonging to 13 classes.\n",
      "\n",
      "Testing Data:\n",
      "Found 5047 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    brightness_range = [0.8, 1.2]\n",
    ")\n",
    "\n",
    "print(\"Training Data:\")\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/train\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"\\nValidation Data:\")\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/val\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "print(\"\\nTesting Data:\")\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    \"the_final_sortdown/test\",\n",
    "    class_mode='categorical',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    include_top = False,\n",
    "    weights ='imagenet',\n",
    "    input_shape = (224,224,3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "num_classes = len(train_data.class_indices)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=5,          \n",
    "    restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindychen/.pyenv/versions/3.9.16/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 226ms/step - accuracy: 0.7679 - loss: 0.7594 - val_accuracy: 0.8987 - val_loss: 0.3101\n",
      "Epoch 2/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 232ms/step - accuracy: 0.8897 - loss: 0.3254 - val_accuracy: 0.9163 - val_loss: 0.2405\n",
      "Epoch 3/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 234ms/step - accuracy: 0.9067 - loss: 0.2612 - val_accuracy: 0.9284 - val_loss: 0.2038\n",
      "Epoch 4/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 228ms/step - accuracy: 0.9180 - loss: 0.2243 - val_accuracy: 0.9316 - val_loss: 0.1908\n",
      "Epoch 5/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 234ms/step - accuracy: 0.9259 - loss: 0.2044 - val_accuracy: 0.9388 - val_loss: 0.1775\n",
      "Epoch 6/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 222ms/step - accuracy: 0.9371 - loss: 0.1742 - val_accuracy: 0.9408 - val_loss: 0.1613\n",
      "Epoch 7/7\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 226ms/step - accuracy: 0.9388 - loss: 0.1559 - val_accuracy: 0.9418 - val_loss: 0.1592\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs = 7, \n",
    "    callbacks = [early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 140ms/step - accuracy: 0.9509 - loss: 0.1257\n",
      "Test accuarcy: 0.94\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(f\"Test accuarcy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 144ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     battery       0.98      0.97      0.97       265\n",
      "  biological       0.99      0.98      0.98       268\n",
      " brown-glass       0.80      0.92      0.85       173\n",
      "   cardboard       0.98      0.94      0.96       360\n",
      "     clothes       0.99      0.99      0.99      1493\n",
      "       glass       0.46      0.16      0.23       140\n",
      " green-glass       0.86      0.87      0.86       175\n",
      "       metal       0.97      0.92      0.94       333\n",
      "       paper       0.96      0.98      0.97       470\n",
      "     plastic       0.95      0.91      0.93       381\n",
      "       shoes       0.96      0.99      0.97       545\n",
      "       trash       0.96      0.94      0.95       235\n",
      " white-glass       0.64      0.94      0.76       209\n",
      "\n",
      "    accuracy                           0.94      5047\n",
      "   macro avg       0.88      0.88      0.88      5047\n",
      "weighted avg       0.94      0.94      0.93      5047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding Precision, Recall, and F1\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(test_data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_data.classes\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', '.heading', 'Unnamed: 2', '..1', 'Unnamed: 4', 'Process', 'Total', 'Total.1', 'eco-costs of', 'eco-costs of.1', 'eco-costs of.2', 'eco-costs of.3', 'Carbon ', 'Carbon .1', 'CED', 'ReCiPe2016', 'ReCiPe2016.1', 'ReCiPe', 'ReCiPe.1', 'ReCiPe.2', 'ReCiPe.3', 'ReCiPe.4', 'ReCiPe.5', 'EF 3.1', 'EF 3.1.1', 'carbon', 'pollutants', 'water', 'biodiversity', 'resources', 'ClassyFire', 'chemicals,plastics, and wood', 'Note:', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try loading with ISO-8859-1 encoding\n",
    "df = pd.read_csv(\"../Datasets/Idemat_2025RevA6.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Check the columns\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          process     co2_kg\n",
      "4    Leather Chrome tanning - hides from Argentia   2.386666\n",
      "5   Leather Vegetable tanning - hides from Europe   2.695087\n",
      "6  Wool (from Australia transported to Rotterdam)  11.712053\n",
      "7                          Wool at farm Australia  11.664082\n",
      "8                 wool, greasy, at farm Australia   5.832041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/18gsxnh94yn8bvylm1wq909m0000gn/T/ipykernel_15535/4237926682.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[\"co2_kg\"] = pd.to_numeric(df_filtered[\"co2_kg\"], errors=\"coerce\")\n",
      "/var/folders/gp/18gsxnh94yn8bvylm1wq909m0000gn/T/ipykernel_15535/4237926682.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered.dropna(subset=[\"process\", \"co2_kg\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../Datasets/Idemat_2025RevA6.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Select only the needed columns\n",
    "df_filtered = df[[ \"Process\", \"carbon\"]]\n",
    "\n",
    "# Rename columns for easier access\n",
    "df_filtered.columns = [\"process\", \"co2_kg\"]\n",
    "df_filtered[\"co2_kg\"] = pd.to_numeric(df_filtered[\"co2_kg\"], errors=\"coerce\")\n",
    "\n",
    "df_filtered.dropna(subset=[\"process\", \"co2_kg\"], inplace=True)\n",
    "\n",
    "co2_lookup = dict(zip(df_filtered[\"process\"], df_filtered[\"co2_kg\"]))\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete\n",
    "\n",
    "cnn_class_to_process = {\n",
    "    \"plastic\": \"Polyethylene (Europe)\",                          \n",
    "    \"metal\": \"Aluminum (Europe)\",                               \n",
    "    \"cardboard\": \"Corrugated board - bleached\",                 \n",
    "    \"glass\": \"Glass - packaging clear\",                         \n",
    "    \"paper\": \"Paper - newsprint\",                                \n",
    "    \"clothes\": \"Cotton fibres India - rainfed\",                  \n",
    "    \"shoes\": \"Leather Vegetable tanning - hides from Europe\",    \n",
    "    \"battery\": \"Nickel metal hydride battery (NiMH)\",            \n",
    "    \"biological\": \"Food waste - average\",                       \n",
    "    \"trash\": \"Municipal solid waste - unsorted\",                 \n",
    "    \"brown-glass\": \"Glass - packaging brown\",\n",
    "    \"green-glass\": \"Glass - packaging green\",\n",
    "    \"white-glass\": \"Glass - packaging clear\"\n",
    "}\n",
    "\n",
    "\n",
    "cnn_class_to_co2 = {\n",
    "    label: co2_lookup.get(material, 1.0)  \n",
    "    for label, material in cnn_class_to_process.items()\n",
    "}\n",
    "\n",
    "\n",
    "correct_actions = {\n",
    "    \"cardboard\": 0,   # Recycle\n",
    "    \"clothes\": 1,     # Donate\n",
    "    \"battery\": 4,     # Hazardous\n",
    "    \"brown-glass\":0,  # Recycle\n",
    "    \"glass\": 0,       # Recycle\n",
    "    \"green-glass\" : 0,# Recycle\n",
    "    \"metal\": 0,       # Recycle\n",
    "    \"paper\": 0,       # Recycle\n",
    "    \"plastic\": 0,     # Recycle\n",
    "    \"shoes\": 1,       # Donate\n",
    "    \"white-glass\": 0, # Recycle \n",
    "    \"trash\" : 2,      # Landfill\n",
    "    \"biological\": 3   # Compost\n",
    "    \n",
    "}\n",
    "\n",
    "class WasteDisposalEnv(Env):\n",
    "    def __init__(self, cnn_class_to_co2, correct_actions):\n",
    "        super(WasteDisposalEnv, self).__init__()\n",
    "        self.cnn_class_to_co2 = cnn_class_to_co2\n",
    "        self.correct_actions = correct_actions\n",
    "        self.classes = list(cnn_class_to_co2.keys())\n",
    "        self.action_space = Discrete(5)  # [Recycle, Donate, Landfill, Compost, Hazardous]\n",
    "        self.observation_space = Discrete(len(self.classes))\n",
    "        self.current_class = None\n",
    "        \n",
    "    # Initialize stats tracker\n",
    "        self.stats = {\n",
    "            \"white-glass_recyclable\": 0,\n",
    "            \"white-glass_nonrecyclable\": 0\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_class = random.choice(self.classes)\n",
    "        obs = self.classes.index(self.current_class)\n",
    "        return obs,{}\n",
    "\n",
    "    def step(self, action):\n",
    "        co2 = self.cnn_class_to_co2[self.current_class]\n",
    "\n",
    "        correct_action = self.correct_actions.get(self.current_class, 2) \n",
    "\n",
    "        if self.current_class == \"white-glass\":\n",
    "            if random.random() < 0.8:\n",
    "                correct_action = 0  # Recyclable\n",
    "                self.stats[\"white-glass_recyclable\"] += 1\n",
    "            else:\n",
    "                correct_action = 2  # Non-recyclable\n",
    "                self.stats[\"white-glass_nonrecyclable\"] += 1\n",
    "\n",
    "        reward = co2 if action == correct_action else -co2\n",
    "        terminated = True\n",
    "        truncated = False\n",
    "        obs, _ = self.reset()\n",
    "\n",
    "        return obs, reward, terminated, truncated, {\n",
    "            \"class\": self.current_class,\n",
    "            \"co2\": co2,\n",
    "            \"action\": action,\n",
    "            \"correct\": correct_action\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -0.594   |\n",
      "| time/              |          |\n",
      "|    fps             | 6604     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | -0.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4536        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059765693 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.0395     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.102      |\n",
      "|    value_loss           | 0.972       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 0.194       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4185        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060517147 |\n",
      "|    clip_fraction        | 0.897       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.484       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.163      |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1           |\n",
      "|    ep_rew_mean          | 0.385       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4051        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070206836 |\n",
      "|    clip_fraction        | 0.936       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0585     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.765       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.168      |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1          |\n",
      "|    ep_rew_mean          | 0.691      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 3987       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12162011 |\n",
      "|    clip_fraction        | 0.887      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.582     |\n",
      "|    explained_variance   | 0.0606     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.25       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.156     |\n",
      "|    value_loss           | 1.18       |\n",
      "----------------------------------------\n",
      "Predicted class: battery, Action: 3, Reward: 1.0\n",
      "Predicted class: brown-glass, Action: 0, Reward: 1.0\n",
      "Predicted class: trash, Action: 0, Reward: 1.0\n",
      "Predicted class: clothes, Action: 1, Reward: 1.0\n",
      "Predicted class: metal, Action: 2, Reward: 1.0\n"
     ]
    }
   ],
   "source": [
    "env = WasteDisposalEnv(cnn_class_to_co2, correct_actions)\n",
    "check_env(env)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "model.save(\"ppo_waste_disposal\")\n",
    "\n",
    "# Test\n",
    "obs, _ = env.reset()\n",
    "for _ in range(5):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    print(f\"Predicted class: {info['class']}, Action: {action}, Reward: {reward}\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 20:33:10.083 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-30 20:33:10.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "agent = PPO.load(\"ppo_waste_disposal.zip\")  \n",
    "\n",
    "cnn_class_to_process = {\n",
    "    \"plastic\": \"Polyethylene (Europe)\",  \n",
    "    \"metal\": \"Aluminium sheet rolling Europe\", \n",
    "    \"cardboard\": \"Corrugated board - unbleached\",  \n",
    "    \"glass\": \"Glass - packaging mixed\", \n",
    "    \"paper\": \"Newsprint paper - 100% recycled\",\n",
    "    \"clothes\": \"Cotton fibres India - rainfed\", \n",
    "    \"shoes\": \"Leather Vegetable tanning - hides from Europe\", \n",
    "    \"battery\": \"Battery - NiMH (Nickel metal hydride)\",  \n",
    "    \"biological\": \"Food waste - average\", \n",
    "    \"trash\": \"Municipal solid waste - unsorted\", \n",
    "    \"brown-glass\": \"Glass - packaging brown\",  \n",
    "    \"green-glass\": \"Glass - packaging green\",  \n",
    "    \"white-glass\": \"Glass - packaging clear\"  \n",
    "}\n",
    "\n",
    "correct_actions = {\n",
    "    \"cardboard\": 0,   # Recycle\n",
    "    \"clothes\": 1,     # Donate\n",
    "    \"battery\": 4,     # Hazardous\n",
    "    \"brown-glass\":0,  # Recycle\n",
    "    \"glass\": 0,       # Recycle\n",
    "    \"green-glass\" : 0,# Recycle\n",
    "    \"metal\": 0,       # Recycle\n",
    "    \"paper\": 0,       # Recycle\n",
    "    \"plastic\": 0,     # Recycle\n",
    "    \"shoes\": 1,       # Donate\n",
    "    \"white-glass\": 0, # Recycle \n",
    "    \"trash\" : 2,      # Landfill\n",
    "    \"biological\": 3   # Compost\n",
    "    \n",
    "}\n",
    "\n",
    "action_names = {0:\"Recycle\",1:\"Donate\",2:\"Landfill\",3:\"Compost\",4:\"Hazardous\"}\n",
    "\n",
    "env = WasteDisposalEnv(cnn_class_to_co2, correct_actions)\n",
    "\n",
    "st.title(\"♻️ Waste Disposal RL Demo\")\n",
    "st.write(\"Pick a waste type and see what our agent recommends.\")\n",
    "\n",
    "choice = st.selectbox(\"Which waste item?\", env.classes)\n",
    "if st.button(\"Get Recommendation\"):\n",
    "\n",
    "    obs = env.classes.index(choice)\n",
    "  \n",
    "    action, _ = agent.predict(obs, deterministic=True)\n",
    "    co2 = cnn_class_to_co2[choice]\n",
    "    st.markdown(f\"**Recommended Action:** {action_names[action]}\")\n",
    "    st.markdown(f\"**Estimated CO₂ impact:** {co2:.2f} kg CO₂e\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
